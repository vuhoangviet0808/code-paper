{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxASrxpfpPh8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import  DataLoader\n",
    "from torch_geometric.data import HeteroData, Data, Dataset, Batch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn as nn\n",
    "from torch.nn import Sequential as Seq, Linear as Lin, ReLU, ELU, Sigmoid, BatchNorm1d as BN, ReLU6 as ReLU6\n",
    "import scipy.io\n",
    "from torch_geometric.nn import HeteroConv, SAGEConv\n",
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(num, num_AP, num_UE, optimize = False):\n",
    "    M = num_AP  # number of access points\n",
    "    K = num_UE  # number of terminals\n",
    "    D = 0.5  # in kilometer\n",
    "    tau = 20  # training length\n",
    "    U, S, V = np.linalg.svd(np.random.randn(tau, tau))\n",
    "    B = 20  # MHz\n",
    "    Hb = 15  # Base station height in m\n",
    "    Hm = 1.65  # Mobile height in m\n",
    "    f = 1900  # Frequency in MHz\n",
    "    aL = (1.1 * np.log10(f) - 0.7) * Hm - (1.56 * np.log10(f) - 0.8)\n",
    "    L = 46.3 + 33.9 * np.log10(f) - 13.82 * np.log10(Hb) - aL\n",
    "    power_f = 0.1  # uplink power: 100 mW\n",
    "    noise_p = 10 ** ((-203.975 + 10 * np.log10(20 * 10**6) + 9) / 10)  # noise power\n",
    "    Pu = power_f / noise_p  # normalized receive SNR\n",
    "    Pp = Pu  # pilot power\n",
    "    sigma_shd = 8  # in dB\n",
    "    D_cor = 0.1\n",
    "    d0 = 0.01  # km\n",
    "    d1 = 0.05  # km\n",
    "    N = num  # realizations\n",
    "\n",
    "    R_cf_min = np.zeros(N)\n",
    "    R_cf_opt_min = np.zeros(N)\n",
    "    R_cf_user = np.zeros((N, K))\n",
    "\n",
    "    directs = np.zeros((N, K))  \n",
    "    corsses = np.zeros((N, K, K)) \n",
    "    betas = np.zeros((N, M, K))  \n",
    "    x_value = np.zeros((N, K))\n",
    "    n = 0\n",
    "    while n < N:\n",
    "        valid = False  \n",
    "        while not valid:  \n",
    "            try:\n",
    "                AP = np.zeros((M, 2, 9))\n",
    "                AP[:, :, 0] = np.random.uniform(-D/2, D/2, (M, 2))\n",
    "\n",
    "                D1 = np.zeros((M, 2))\n",
    "                D1[:, 0] = D1[:, 0] + D*np.ones(M)\n",
    "                AP[:, :, 1] = AP[:, :, 0] + D1\n",
    "\n",
    "                D2 = np.zeros((M, 2))\n",
    "                D2[:, 1] = D2[:, 1] + D*np.ones(M)\n",
    "                AP[:, :, 2] = AP[:, :, 0] + D2\n",
    "\n",
    "                D3 = np.zeros((M, 2))\n",
    "                D3[:, 0] = D3[:, 0] - D*np.ones(M)\n",
    "                AP[:, :, 3] = AP[:, :, 0] + D3\n",
    "\n",
    "                D4 = np.zeros((M, 2))\n",
    "                D4[:, 1] = D4[:, 1] - D*np.ones(M)\n",
    "                AP[:, :, 4] = AP[:, :, 0] + D4\n",
    "\n",
    "                D5 = np.zeros((M, 2))\n",
    "                D5[:, 0] = D5[:, 0] + D*np.ones(M)\n",
    "                D5[:, 1] = D5[:, 1] - D*np.ones(M)\n",
    "                AP[:, :, 5] = AP[:, :, 0] + D5\n",
    "\n",
    "                D6 = np.zeros((M, 2))\n",
    "                D6[:, 0] = D6[:, 0] - D*np.ones(M)\n",
    "                D6[:, 1] = D6[:, 1] - D*np.ones(M)\n",
    "                AP[:, :, 6] = AP[:, :, 0] + D6\n",
    "\n",
    "                D7 = np.zeros((M, 2))\n",
    "                D7 = D7 + D*np.ones((M, 2))\n",
    "                AP[:, :, 7] = AP[:, :, 0] + D7\n",
    "\n",
    "                D8 = np.zeros((M, 2))\n",
    "                D8 = D8 - D*np.ones((M, 2))\n",
    "                AP[:, :, 8] = AP[:, :, 0] + D8\n",
    "\n",
    "                # Initialize Ter positions\n",
    "                Ter = np.zeros((K, 2, 9))\n",
    "                Ter[:, :, 0] = np.random.uniform(-D/2, D/2, (K, 2))\n",
    "\n",
    "                D1 = np.zeros((K, 2))\n",
    "                D1[:, 0] = D1[:, 0] + D*np.ones(K)\n",
    "                Ter[:, :, 1] = Ter[:, :, 0] + D1\n",
    "\n",
    "                D2 = np.zeros((K, 2))\n",
    "                D2[:, 1] = D2[:, 1] + D*np.ones(K)\n",
    "                Ter[:, :, 2] = Ter[:, :, 0] + D2\n",
    "\n",
    "                D3 = np.zeros((K, 2))\n",
    "                D3[:, 0] = D3[:, 0] - D*np.ones(K)\n",
    "                Ter[:, :, 3] = Ter[:, :, 0] + D3\n",
    "\n",
    "                D4 = np.zeros((K, 2))\n",
    "                D4[:, 1] = D4[:, 1] - D*np.ones(K)\n",
    "                Ter[:, :, 4] = Ter[:, :, 0] + D4\n",
    "\n",
    "                D5 = np.zeros((K, 2))\n",
    "                D5[:, 0] = D5[:, 0] + D*np.ones(K)\n",
    "                D5[:, 1] = D5[:, 1] - D*np.ones(K)\n",
    "                Ter[:, :, 5] = Ter[:, :, 0] + D5\n",
    "\n",
    "                D6 = np.zeros((K, 2))\n",
    "                D6[:, 0] = D6[:, 0] - D*np.ones(K)\n",
    "                D6[:, 1] = D6[:, 1] + D*np.ones(K)\n",
    "                Ter[:, :, 6] = Ter[:, :, 0] + D6\n",
    "\n",
    "                D7 = np.zeros((K, 2))\n",
    "                D7 = D7 + D*np.ones((K, 2))\n",
    "                Ter[:, :, 7] = Ter[:, :, 0] + D7\n",
    "\n",
    "                D8 = np.zeros((K, 2))\n",
    "                D8 = D8 - D*np.ones((K, 2))\n",
    "                Ter[:, :, 8] = Ter[:, :, 0] + D8\n",
    "\n",
    "                Dist = np.zeros((M, M))\n",
    "                Cor = np.zeros((M, M))\n",
    "                for m1 in range(M):\n",
    "                    for m2 in range(M):\n",
    "                        Dist[m1, m2] = np.min([np.linalg.norm(AP[m1, :, 0] - AP[m2, :, i]) for i in range(9)])\n",
    "                        Cor[m1, m2] = np.exp(-np.log(2) * Dist[m1, m2] / D_cor)\n",
    "\n",
    "                A1 = np.linalg.cholesky(Cor)\n",
    "                x1 = np.random.randn(M, 1)\n",
    "                sh_AP = A1 @ x1\n",
    "                for m in range(M):\n",
    "                    sh_AP[m] = (1/np.sqrt(2)) * sigma_shd * sh_AP[m] / np.linalg.norm(A1[m, :])\n",
    "\n",
    "                Dist = np.zeros((K, K))\n",
    "                Cor = np.zeros((K, K))\n",
    "                for k1 in range(K):\n",
    "                    for k2 in range(K):\n",
    "                        Dist[k1, k2] = np.min([np.linalg.norm(Ter[k1, :, 0] - Ter[k2, :, i]) for i in range(9)])\n",
    "                        Cor[k1, k2] = np.exp(-np.log(2) * Dist[k1, k2] / D_cor)\n",
    "\n",
    "                A2 = np.linalg.cholesky(Cor)\n",
    "                x2 = np.random.randn(K, 1)\n",
    "                sh_Ter = A2 @ x2\n",
    "\n",
    "                valid = True\n",
    "\n",
    "            except np.linalg.LinAlgError:\n",
    "                #print(\"Matrix not positive definite, retrying...\")\n",
    "                continue\n",
    "\n",
    "        for k in range(K):\n",
    "            sh_Ter[k] = (1/np.sqrt(2))*sigma_shd*sh_Ter[k]/np.linalg.norm(A2[k,:])\n",
    "\n",
    "        Z_shd = np.zeros((M,K))\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                Z_shd[m,k] = sh_AP[m] + sh_Ter[k]\n",
    "\n",
    "        # Large-scale coefficients\n",
    "        BETAA = np.zeros((M, K))\n",
    "        dist = np.zeros((M,K))\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                dist[m, k] = np.min([np.linalg.norm(AP[m,:,i]-Ter[k,:,0]) for i in range(9)])\n",
    "                index = np.argmin([np.linalg.norm(AP[m,:,i]-Ter[k,:,0]) for i in range(9)])\n",
    "                if dist[m, k] < d0:\n",
    "                    betadB = -L - 35 * np.log10(d1) + 20 * np.log10(d1) - 20 * np.log10(d0)\n",
    "                elif d0 <= dist[m, k] <= d1:\n",
    "                    betadB = -L - 35 * np.log10(d1) + 20 * np.log10(d1) - 20 * np.log10(dist[m, k])\n",
    "                else:\n",
    "                    betadB = -L - 35 * np.log10(dist[m, k]) + Z_shd[m, k]\n",
    "                BETAA[m, k] = 10 ** (betadB / 10)\n",
    "\n",
    "        # Pilot assignment: (random choice)\n",
    "        Phii = np.zeros((tau,K))\n",
    "        for k in range(K):\n",
    "            Point = k\n",
    "            Phii[:,k] = U[:,Point]\n",
    "\n",
    "        Phii_cf = Phii\n",
    "\n",
    "\n",
    "        # Compute Gamma matrix\n",
    "        Gammaa = np.zeros((M, K))\n",
    "        mau = np.zeros((M,K))\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                mau[m,k] = np.linalg.norm((BETAA[m,:]**(1/2)*(Phii_cf[:,k].T@Phii_cf)))**2\n",
    "                Gammaa[m, k] = tau * Pp * BETAA[m, k]**2 / (tau * Pp * mau[m,k] + 1)\n",
    "\n",
    "        # SINR and rate calculation\n",
    "        SINR = np.zeros(K)\n",
    "        R_cf = np.zeros(K)\n",
    "\n",
    "        PC = np.zeros((K,K))\n",
    "        for ii in range(K):\n",
    "            for k in range(K):\n",
    "                PC[ii,k] = np.sum((Gammaa[:,k]/BETAA[:,k]*BETAA[:,ii])*(Phii_cf[:,k].T@Phii_cf[:,ii]))\n",
    "        PC1 = (np.abs(PC))**2\n",
    "        \n",
    "        for k in range(K):\n",
    "            deno1 = 0\n",
    "            for m in range(M):\n",
    "                deno1 += Gammaa[m,k]*np.sum(BETAA[m,:])\n",
    "            \n",
    "            SINR[k] = Pu*(np.sum(Gammaa[:,k]))**2/(np.sum(Gammaa[:,k]) + Pu*deno1 + Pu*np.sum(PC1[:,k]) - Pu*PC1[k,k])\n",
    "            R_cf[k] = np.log2(1+SINR[k])\n",
    "\n",
    "        stepp = 5\n",
    "        Ratestep = np.zeros((stepp, K))\n",
    "        Ratestep[0,:] = R_cf\n",
    "\n",
    "        for st in range(1, stepp): \n",
    "            minvalue, minindex = np.min(Ratestep[st - 1, :]), np.argmin(Ratestep[st - 1, :])\n",
    "            Mat = np.zeros((tau, tau)) - Pu * np.sum(BETAA[:, minindex]) * np.outer(Phii_cf[:, minindex], Phii_cf[:, minindex])\n",
    "            for kk in range(K):\n",
    "                Mat += Pu * np.sum(BETAA[:, kk]) * (Phii_cf[:, kk]@Phii_cf[:, kk].T)\n",
    "        \n",
    "            U1, S1, V1 = np.linalg.svd(Mat, full_matrices=True)\n",
    "            Phii_cf[:, minindex] = U1[:, tau-1]\n",
    "\n",
    "\n",
    "        Gammaa = np.zeros((M, K))\n",
    "        mau = np.zeros((M, K))\n",
    "\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                mau[m, k] = np.linalg.norm(\n",
    "                    (BETAA[m, :]**0.5) * (Phii_cf[:, k].T@Phii_cf)**2\n",
    "                )**2\n",
    "        for m in range(M):\n",
    "            for k in range(K):\n",
    "                Gammaa[m, k] = tau * Pp * BETAA[m, k]**2 / (tau * Pp * mau[m, k] + 1)\n",
    "\n",
    "        SINR = np.zeros(K)\n",
    "        PC = np.zeros((K, K))\n",
    "\n",
    "        for ii in range(K):\n",
    "            for k in range(K):\n",
    "                PC[ii, k] = np.sum((Gammaa[:, k] / BETAA[:, k]) * BETAA[:, ii]) * np.dot(Phii_cf[:, k], Phii_cf[:, ii])\n",
    "        PC1 = np.abs(PC)**2\n",
    "        for k in range(K):\n",
    "            deno1 = 0\n",
    "            for m in range(M):\n",
    "                deno1 += Gammaa[m, k] * np.sum(BETAA[m, :])\n",
    "            SINR[k] = Pu * (np.sum(Gammaa[:, k]))**2 / (\n",
    "                np.sum(Gammaa[:, k]) + Pu * deno1 + Pu * np.sum(PC1[:, k]) - Pu * PC1[k, k]\n",
    "            )\n",
    "            # Rate calculation\n",
    "            Ratestep[st-1, k] = np.log2(1 + SINR[k])\n",
    "\n",
    "        R_cf_min[n] = np.min(Ratestep[stepp-1, :])\n",
    "        R_cf_user[n,:] = Ratestep[stepp-1, :]\n",
    "\n",
    "        tmin = 2**R_cf_min[n]-1\n",
    "        tmax=2**(2*R_cf_min[n]+1.2)-1\n",
    "        epsi = max(tmin/5,0.01)\n",
    "\n",
    "        BETAAn = BETAA * Pu\n",
    "        Gammaan = Gammaa * Pu\n",
    "        PhiPhi = np.zeros((K, K))\n",
    "        Te1 = np.zeros((K, K))\n",
    "        Te2 = np.zeros((K, K))\n",
    "        direct = np.zeros(K)\n",
    "\n",
    "        for ii in range(K):\n",
    "            for k in range(K):\n",
    "                PhiPhi[ii, k] = np.linalg.norm(Phii_cf[:, ii].T@Phii_cf[:, k])\n",
    "\n",
    "        for ii in range(K):\n",
    "            direct[ii] = np.sum(Gammaan[:, ii])\n",
    "            for k in range(K):\n",
    "                Te1[ii, k] = np.sum(BETAAn[:, ii] * Gammaan[:, k])\n",
    "                Te2[ii, k] = (\n",
    "                    np.sum((Gammaan[:, k] / BETAA[:, k]) * BETAA[:, ii])**2\n",
    "                    * PhiPhi[k, ii]**2\n",
    "                )\n",
    "                if ii == k:\n",
    "                    Te2[ii, k] = 0\n",
    "\n",
    "\n",
    "        # Max-min power allocation using CVXPY\n",
    "        if optimize:\n",
    "            x = cp.Variable(K)\n",
    "            tmin = 2**R_cf_min[n] - 1\n",
    "            tmax = 2**(2 * R_cf_min[n] + 1.2) - 1\n",
    "            epsi = max(tmin / 5, 0.05)\n",
    "\n",
    "            while tmax - tmin > epsi:\n",
    "                tnext = (tmax + tmin) / 2\n",
    "\n",
    "                x = cp.Variable(K)\n",
    "                constraints = []\n",
    "                for k in range(K):\n",
    "                    left_term = Te1[:, k].T @ x\n",
    "\n",
    "                    if k > 0:\n",
    "                        top_part = Te2[:k, k]\n",
    "                        top_x = x[:k]\n",
    "                    else:\n",
    "                        top_part = np.array([])  \n",
    "                        top_x = np.array([])\n",
    "\n",
    "                    if k < K - 1:\n",
    "                        bottom_part = Te2[k+1:, k]\n",
    "                        bottom_x = x[k+1:]\n",
    "                    else:\n",
    "                        bottom_part = np.array([])\n",
    "                        bottom_x = np.array([])\n",
    "\n",
    "                    if top_part.size > 0 and bottom_part.size > 0:\n",
    "                        middle_term = cp.hstack([top_part, bottom_part]).T @ cp.hstack([top_x, bottom_x])\n",
    "                    elif top_part.size > 0:\n",
    "                        middle_term = top_part.T @ top_x\n",
    "                    elif bottom_part.size > 0:\n",
    "                        middle_term = bottom_part.T @ bottom_x\n",
    "                    else:\n",
    "                        middle_term = 0\n",
    "                    \n",
    "                    right_term = (1 / tnext) * (np.sum(Gammaan[:, k]))**2 * x[k]\n",
    "                    constraints.append(left_term + middle_term + np.sum(Gammaan[:, k]) <= right_term)\n",
    "\n",
    "                constraints += [x >= 0, x <= 1]\n",
    "        \n",
    "                prob = cp.Problem(cp.Minimize(0), constraints)\n",
    "                prob.solve()\n",
    "\n",
    "                if prob.status == cp.OPTIMAL:\n",
    "                    #print(f\"Problem is feasible at tnext = {tnext}\")\n",
    "                    tmin = tnext\n",
    "                else:\n",
    "                    #print(f\"Problem not feasible at tnext = {tnext}\")\n",
    "                    tmax = tnext\n",
    "            if(x.value is None):\n",
    "                continue\n",
    "            x_value[n] = x.value\n",
    "            R_cf_opt_min[n] = np.log2(1 + tmin)\n",
    "        cross = Te1 + Te2\n",
    "        directs[n, :] = direct\n",
    "        corsses[n, :, :] = cross\n",
    "        betas[n, :, :] = BETAAn\n",
    "        n += 1\n",
    "    if optimize:\n",
    "        return betas, directs, corsses, R_cf_opt_min, x_value\n",
    "    return betas, directs, corsses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_layouts = 10000\n",
    "test_layouts = 200\n",
    "M = 30\n",
    "K = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_train , direct_train, cross_train = generate_data(train_layouts, M, K, optimize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_test, direct_test, corsses_test, R_cf_opt_min, x_value = generate_data(test_layouts, M, K, optimize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qf570KmTyQbX"
   },
   "outputs": [],
   "source": [
    "cross_train = cross_train.transpose(0,2,1)\n",
    "cross_test = corsses_test.transpose(0,2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sYyr8aCByTVt"
   },
   "outputs": [],
   "source": [
    "def normalize_data(train_data,test_data):\n",
    "    train_mean = np.mean(train_data)\n",
    "    train_std = np.std(train_data)\n",
    "    norm_train = (train_data)/train_std\n",
    "    norm_test = (test_data)/train_std\n",
    "    n1, n2 = norm_train.shape[0], norm_test.shape[0]\n",
    "    return norm_train, norm_test\n",
    "norm_train_losses, norm_test_losses = normalize_data(beta_train**(1/2), beta_test**(1/2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdJ9_u8HycEQ"
   },
   "outputs": [],
   "source": [
    "class PCDataset(Dataset):\n",
    "    def __init__(self, norm_losses, direct, cross, KM):\n",
    "        self.norm_losses = norm_losses\n",
    "        self.direct = torch.tensor(direct, dtype=torch.float)\n",
    "        self.cross = torch.tensor(cross, dtype=torch.float)\n",
    "        self.KM = KM\n",
    "        self.get_cg()\n",
    "        self.process()\n",
    "\n",
    "    def build_graph(self, idx):\n",
    "        edge_feature = self.norm_losses[idx, :, :].reshape((self.KM[0] * self.KM[1], 1), order='F')\n",
    "        edge_feature = np.concatenate((edge_feature, np.ones_like(edge_feature)), axis=-1)\n",
    "        edge_feature = torch.tensor(edge_feature, dtype=torch.float)\n",
    "\n",
    "        edge_index = torch.tensor(self.adj, dtype=torch.long).t().contiguous()\n",
    "        edge_index_t = torch.tensor(self.adj_t, dtype=torch.long).t().contiguous()\n",
    "        ue_features = torch.ones((self.KM[0], 1))\n",
    "        ap_features = torch.ones((self.KM[1], 1))\n",
    "\n",
    "        data = HeteroData()\n",
    "        data['UE'].x = ue_features\n",
    "        data['AP'].x = ap_features\n",
    "        data['UE', 'com-by', 'AP'].edge_index = edge_index\n",
    "        data['UE', 'com-by', 'AP'].edge_attr = edge_feature\n",
    "        data['AP', 'com', 'UE'].edge_index = edge_index_t\n",
    "        data['AP', 'com', 'UE'].edge_attr = edge_feature\n",
    "\n",
    "        return data\n",
    "\n",
    "    def get_cg(self):\n",
    "        self.adj = []\n",
    "        self.adj_t = []\n",
    "        for i in range(self.KM[0]):\n",
    "            for j in range(self.KM[1]):\n",
    "                self.adj.append([i, j])\n",
    "                self.adj_t.append([j, i])\n",
    "\n",
    "    def process(self):\n",
    "        self.graph_list = [self.build_graph(i) for i in range(len(self.direct))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.direct)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.graph_list[index], self.direct[index], self.cross[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLDl46ZqygYW"
   },
   "outputs": [],
   "source": [
    "def collate(samples):\n",
    "    '''Pytorch Geometric collate function'''\n",
    "    graphs, direct, cross = map(list, zip(*samples))\n",
    "    batched_graph = Batch.from_data_list(graphs)\n",
    "    return batched_graph, torch.stack(direct), torch.stack(cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbgSJEeryiJi"
   },
   "outputs": [],
   "source": [
    "train_data = PCDataset(norm_train_losses, direct_train, cross_train, (K, M))\n",
    "test_data = PCDataset(norm_test_losses, direct_test, cross_test, (K, M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAbfIs250xcP"
   },
   "source": [
    "# Mục mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJpj7rEfylHh"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_data, batch_size, shuffle=True, collate_fn=collate)\n",
    "test_loader = DataLoader(test_data, test_layouts, shuffle=False, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46z6FzDvymjV"
   },
   "outputs": [],
   "source": [
    "def rate_loss(allocs, directlink_channel_losses, crosslink_channel_losses, test_mode = False):\n",
    "    SINRs_numerators = allocs * directlink_channel_losses**2\n",
    "    SINRs_denominators = torch.squeeze(torch.matmul(crosslink_channel_losses, torch.unsqueeze(allocs, axis=-1))) + directlink_channel_losses\n",
    "    SINRs = SINRs_numerators / SINRs_denominators\n",
    "    rates = torch.log2(1 + SINRs)\n",
    "    min_rate = torch.min(rates, dim = 1)[0] # take min\n",
    "    if test_mode:\n",
    "        return min_rate\n",
    "    else:\n",
    "        return -torch.mean(min_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jXm55Q1MyoHJ"
   },
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, input_dim, node_dim, **kwargs):\n",
    "        super(EdgeConv, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin = MLP([input_dim, 32])\n",
    "        self.res_lin = Lin(node_dim, 32)\n",
    "        self.bn = BN(32)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "\n",
    "        feat_src, feat_dst = x\n",
    "\n",
    "\n",
    "        out = self.propagate(edge_index=edge_index, x=(feat_src, feat_dst), edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "        return self.bn(out + self.res_lin(feat_dst))\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr):\n",
    "        # Tạo ra thông điệp từ các nút nguồn, nút đích và đặc tính cạnh\n",
    "        out = torch.cat([x_j, x_i, edge_attr], dim=1)\n",
    "        return self.lin(out)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Cập nhật giá trị nút đích sau khi tập hợp\n",
    "        return aggr_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fDGAbhqVyp-4"
   },
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv(4, 1),\n",
    "            ('AP', 'com', 'UE'): EdgeConv(4, 1)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv(66, 32),\n",
    "            ('AP', 'com', 'UE'): EdgeConv(66, 32)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv3 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv(66, 32),\n",
    "            ('AP', 'com', 'UE'): EdgeConv(66, 32)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.mlp = MLP([32, 16])\n",
    "        self.mlp = nn.Sequential(*[self.mlp, Seq(Lin(16, 1), Sigmoid())])\n",
    "\n",
    "    def forward(self,x_dict, edge_index_dict, edge_attr_dict):\n",
    "        out = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv2(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv3(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.mlp(out['UE'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YnBQvvFyyrdz"
   },
   "outputs": [],
   "source": [
    "model = RGCN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJ8dsxg3yszd"
   },
   "outputs": [],
   "source": [
    "def train_model(epoch, model, optimizer, train_loader):\n",
    "    \"\"\" Train for one epoch. \"\"\"\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    for batch_idx, (data, d_train, c_train) in enumerate(train_loader):\n",
    "        K = d_train.shape[-1]\n",
    "        n = len(data['UE'].x)\n",
    "        bs = len(data['UE'].x) // K\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Lấy các đặc trưng nút từ từ điển x_dict\n",
    "        user_feats = data['AP'].x\n",
    "        item_feats = data['UE'].x\n",
    "        node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "\n",
    "        # Truyền qua mô hình, bao gồm cả edge_attr_dict\n",
    "        output = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "\n",
    "        # Tính loss và thực hiện backpropagation\n",
    "        loss = rate_loss(output, d_train, c_train)\n",
    "        loss.backward()\n",
    "\n",
    "        loss_all += loss.item() * bs\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_all / len(train_loader.dataset)\n",
    "\n",
    "def test_model(loader, model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for (data, d_test, c_test) in loader:\n",
    "            K = d_test.shape[-1]\n",
    "            n = len(data['UE'].x)\n",
    "            bs = len(data['UE'].x) // K\n",
    "\n",
    "            # Lấy các đặc trưng nút từ từ điển x_dict\n",
    "            user_feats = data['AP'].x\n",
    "            item_feats = data['UE'].x\n",
    "            # Create a dictionary for node features\n",
    "            node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "\n",
    "            output = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "\n",
    "            # Tính loss\n",
    "            loss = rate_loss(output, d_test, c_test)\n",
    "            correct += loss.item() * bs\n",
    "\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q0acdxv18R11",
    "outputId": "e6b64da4-57b4-46c1-ac42-6059d1d592c9"
   },
   "outputs": [],
   "source": [
    "record = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            test_rate = test_model(test_loader, model)\n",
    "            train_rate = test_model(train_loader, model)\n",
    "        print(f'Epoch {epoch:03d}, Train Rate: {train_rate:.4f}, Test Rate: {test_rate:.4f}')\n",
    "        record.append([train_rate, test_rate])\n",
    "\n",
    "    train_model(epoch, model, optimizer, train_loader )\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyB94R7VbQcb"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "gnn_rates = None\n",
    "start_time = time.time()\n",
    "\n",
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    gnn_rates = rate_loss(output, d_test, c_test, True).flatten().detach().numpy()\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time taken for gnn model:\", (end_time - start_time)/test_layouts, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(gnn_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVvPmDjTRUhX"
   },
   "source": [
    "# Quantum MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uPjW6qyrtBV"
   },
   "source": [
    "# HQGNN Amplitude Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJ4YAp-R00l5",
    "outputId": "8c4459e1-51cf-4c46-b767-2fa8b2943101"
   },
   "outputs": [],
   "source": [
    "pip install pennylane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j85HXPW5Js5y"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "n_qubits = 5\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dzdiSp2LY7b-"
   },
   "outputs": [],
   "source": [
    "n_layers_circuit_X = 2\n",
    "def circuit_X_entangling(weights, n_qubits):\n",
    "    qml.CRX(weights[-1], wires=[n_qubits-1, 0])\n",
    "    for i in range(n_qubits-1):\n",
    "        qml.CRX(weights[i], wires=[i, (i+1)])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_X(inputs, layer_weights):\n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize=True, pad_with=0.)\n",
    "    for l in range(n_layers_circuit_X):\n",
    "        circuit_X_entangling(layer_weights[l], n_qubits)\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "weight_shapes_circuit_X = { \"layer_weights\": (n_layers_circuit_X, n_qubits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HUVr0YnsdC-w"
   },
   "outputs": [],
   "source": [
    "n_layers_circuit_Z = 2 \n",
    "def circuit_Z_entangling(weights, n_qubits):\n",
    "    qml.CRZ(weights[-1], wires=[n_qubits - 1, 0])\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CRZ(weights[i], wires=[i, i + 1])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_Z(inputs, layer_weights):\n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits), normalize=True, pad_with=0.)\n",
    "    for l in range(n_layers_circuit_Z):\n",
    "        circuit_Z_entangling(layer_weights[l], n_qubits)\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "weight_shapes_circuit_Z = { \"layer_weights\": (n_layers_circuit_Z, n_qubits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPtCqEwDI7qk"
   },
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class Q_layer(MessagePassing):\n",
    "    def __init__(self,src_dim, dst_dim, edge_dim, **kwargs):\n",
    "        super(Q_layer, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin_res = qml.qnn.TorchLayer(circuit_Z, weight_shapes_circuit_Z)\n",
    "        self.lin_qml = qml.qnn.TorchLayer(circuit_X, weight_shapes_circuit_X)\n",
    "        self.in_linear = nn.Linear(src_dim + dst_dim + edge_dim, 2 ** n_qubits)\n",
    "        self.bn = BN(2 ** n_qubits)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        feat_src, feat_dst = x\n",
    "        out = self.propagate(edge_index=edge_index, x=(feat_src, feat_dst), edge_attr=edge_attr)\n",
    "        out = out + self.lin_res(feat_dst)\n",
    "        return self.bn(out)\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr):\n",
    "        out = torch.cat([x_j, x_i, edge_attr], dim=1)\n",
    "        out = self.in_linear(out)\n",
    "        out = self.lin_qml(out)\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3P26wasVI878"
   },
   "outputs": [],
   "source": [
    "class RGCN_Hybrid_mid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGCN_Hybrid_mid, self).__init__()\n",
    "        out_dim = 2**n_qubits\n",
    "        edge_dim = 2\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer(1, 1, edge_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer(1, 1, edge_dim,)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer(out_dim, out_dim, edge_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer(out_dim, out_dim, edge_dim)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv3 = HeteroConv({\n",
    "             ('UE', 'com-by', 'AP'): Q_layer(out_dim, out_dim, edge_dim),\n",
    "             ('AP', 'com', 'UE'): Q_layer(out_dim, out_dim, edge_dim)\n",
    "         }, aggr='mean')\n",
    "\n",
    "\n",
    "        \n",
    "        self.mlp = MLP([32, 16])\n",
    "        self.mlp = nn.Sequential(*[self.mlp, Seq(Lin(16, 1), Sigmoid())])\n",
    "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
    "        out = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv2(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv3(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.mlp(out['UE'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrHEZM-pI-GL"
   },
   "outputs": [],
   "source": [
    "model_qml_amplitude = RGCN_Hybrid_mid().to()\n",
    "\n",
    "optimizer_qml_amplitude = torch.optim.Adam(model_qml_amplitude.parameters(), lr=5e-4)\n",
    "scheduler_qml_amplitude = torch.optim.lr_scheduler.StepLR(optimizer_qml_amplitude, step_size=10, gamma=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model_qml_amplitude.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qqgDgSgdI_cL",
    "outputId": "d50a514b-5285-4af1-bc03-63ceeffb45b4"
   },
   "outputs": [],
   "source": [
    "record_edge = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_rate = test_model(test_loader, model_qml_amplitude)\n",
    "        train_rate = test_model(train_loader, model_qml_amplitude)\n",
    "        record_edge.append([train_rate, test_rate])\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch:02d}, Train Rate: {train_rate:.4f}, Test Rate: {test_rate:.4f}')\n",
    "    train_model(epoch, model_qml_amplitude, optimizer_qml_amplitude, train_loader)\n",
    "    scheduler_qml_amplitude.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R106ZaEY9ZsP"
   },
   "outputs": [],
   "source": [
    "gnn_q_rates = None\n",
    "gnn_rates = None\n",
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_2 = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    full = torch.ones_like(output)\n",
    "    all_one_rates = rate_loss(full, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_q_rates = rate_loss(output, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_rates = rate_loss(output_2, d_test, c_test, True).flatten().detach().numpy()\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = test_data['R_cf_opt_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rate, max_rate = 0, 2\n",
    "y_axis = np.arange(0, 1.0, 1/202)\n",
    "opt_rates.sort();gnn_rates.sort(); all_one_rates.sort();gnn_q_rates.sort()\n",
    "gnn_q_rates = np.insert(gnn_q_rates, 0, min_rate); gnn_q_rates = np.insert(gnn_q_rates,201,max_rate)\n",
    "gnn_rates = np.insert(gnn_rates, 0, min_rate); gnn_rates = np.insert(gnn_rates,201,max_rate)\n",
    "all_one_rates = np.insert(all_one_rates, 0, min_rate); all_one_rates = np.insert(all_one_rates,201,max_rate)\n",
    "opt_rates = np.insert(opt_rates, 0, min_rate); opt_rates = np.insert(opt_rates,201,max_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gnn_rates, y_axis, label = 'GNN')\n",
    "#plt.plot(gnn_rates_qml_mid_angle, y_axis, label = 'HQGNN angle')\n",
    "plt.plot(gnn_q_rates, y_axis, label = 'HQGNN amplitude')\n",
    "plt.plot(opt_rates, y_axis, label = 'Optimal')\n",
    "plt.plot(all_one_rates, y_axis, label = 'Maximum Power')\n",
    "plt.xlabel('Minimum rate [bps/Hz]', {'fontsize':16})\n",
    "plt.ylabel('Empirical CDF', {'fontsize':16})\n",
    "plt.legend(fontsize = 12)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KFstzGT-Fs2G",
    "outputId": "17f78007-62bd-417c-ec31-3cf78cee79dd"
   },
   "outputs": [],
   "source": [
    "print(f'QGNN in middle: {np.mean(gnn_q_rates)}')\n",
    "print(f'GNN: {np.mean(gnn_rates)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_test_rates = None\n",
    "gnn_test_rates_q = None\n",
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output_qgnn = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "    gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_test_rates_q = rate_loss(output_qgnn, d_test, c_test, True).flatten().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = np.sum(gnn_test_rates_q > gnn_test_rates)\n",
    "print(f'Number of samples where HQGNN outperforms GNN: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=180)\n",
    "epsilon = 0.001 \n",
    "\n",
    "positions_greater = np.where((gnn_test_rates_q - gnn_test_rates) > epsilon)[0]\n",
    "positions_equal = np.where(np.abs(gnn_test_rates_q - gnn_test_rates) <= epsilon)[0]\n",
    "\n",
    "count_greater = len(positions_greater)\n",
    "count_equal = len(positions_equal)\n",
    "count_not_greater = 200 - count_greater - count_equal\n",
    "\n",
    "labels = ['HQGNN amplitude > GNN', 'HQGNN amplitude ≈ GNN', 'HQGNN angle < GNN']\n",
    "sizes = [count_greater, count_equal, count_not_greater]\n",
    "explode = (0.1, 0.1, 0)  \n",
    "\n",
    "# Remove labels in the pie chart but keep legend\n",
    "ax.pie(sizes, explode=explode, labels=None, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(labels, loc='upper left')\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=180)\n",
    "epsilon = 0.001 \n",
    "\n",
    "positions_greater = np.where((gnn_test_rates_q - gnn_test_rates) > epsilon)[0]\n",
    "positions_equal = np.where(np.abs(gnn_test_rates_q - gnn_test_rates) <= epsilon)[0]\n",
    "\n",
    "\n",
    "count_greater = len(positions_greater)\n",
    "count_equal = len(positions_equal)\n",
    "count_not_greater = 200 - count_greater - count_equal\n",
    "\n",
    "\n",
    "labels = ['HQGNN amplitude > GNN', 'HQGNN amplitude ≈ GNN', 'HQGNN amplitude < GNN']\n",
    "sizes = [count_greater, count_equal, count_not_greater]\n",
    "explode = (0.1, 0.1, 0)  \n",
    "\n",
    "ax.pie(sizes, explode=explode, labels=None, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title('Ratio of HQGNN amplitude position to GNN with error 1e-3')\n",
    "ax.legend(labels, loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('cf_train_5_20_test.mat')\n",
    "len(data['betas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_test_rates = None\n",
    "gnn_test_rates_q = None\n",
    "positions_greater = 0\n",
    "positions_equal = 0\n",
    "positions_less = 0\n",
    "epsilon = 0.001 \n",
    "num = 1000\n",
    "file_name = ['cf_train_5_20_test.mat', 'cf_train_10_30_test.mat', 'cf_train_20_40_test.mat', 'cf_train_20_50_test.mat']\n",
    "#file_name = ['cf_test_6_30.mat']\n",
    "scenarior = [(5, 20), (10, 30), (20, 40), (20, 50)]\n",
    "\n",
    "for i in range(len(file_name)):\n",
    "    data = scipy.io.loadmat(file_name[i])\n",
    "    beta = data['betas'][:num]\n",
    "    direct = data['directs'][:num]\n",
    "    cross = data['corsses'][:num].transpose(0, 2, 1)\n",
    "    \n",
    "    _, norm_losses = normalize_data(beta**(1/2), beta**(1/2))\n",
    "    data = PCDataset(norm_losses, direct, cross, scenarior[i])\n",
    "    loader = DataLoader(data, 100, shuffle=False, collate_fn=collate)\n",
    "    \n",
    "    for batch_idx, (g, d_test, c_test) in enumerate(loader):\n",
    "        K = d_test.shape[-1]\n",
    "        n = len(g['UE'].x)\n",
    "        bs = len(g['UE'].x) // K\n",
    "        user_feats = g['AP'].x\n",
    "        item_feats = g['UE'].x\n",
    "        node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "   \n",
    "        output_qgnn_mid = model_qml_amplitude(node_features, g.edge_index_dict, g.edge_attr_dict).reshape(bs, -1)\n",
    "        output_gnn = model(node_features, g.edge_index_dict, g.edge_attr_dict).reshape(bs, -1)\n",
    "\n",
    "        gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "        gnn_test_rates_q = rate_loss(output_qgnn_mid, d_test, c_test, True).flatten().detach().numpy()\n",
    "        count_greater = np.sum((gnn_test_rates_q - gnn_test_rates) > epsilon)\n",
    "        count_equal = np.sum(np.abs(gnn_test_rates_q - gnn_test_rates) <= epsilon)\n",
    "        positions_greater += count_greater\n",
    "        positions_equal += count_equal\n",
    "        batch_size = len(gnn_test_rates)\n",
    "        positions_less += 100 - count_greater - count_equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(positions_greater,positions_equal,  positions_less)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=180)\n",
    "labels = ['HQGNN amplitude > GNN', 'HQGNN amplitude ≈ GNN', 'HQGNN amplitude < GNN']\n",
    "sizes = [positions_greater, positions_equal, positions_less]\n",
    "explode = (0.1, 0.1, 0)  \n",
    "\n",
    "\n",
    "ax.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "ax.legend()\n",
    "plt.title(f'Error {epsilon}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angle Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "n_qubits = 5\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_circuit_X2 = 1\n",
    "def circuit_X2_entangling(weights, n_qubits):\n",
    "    qml.CRX(weights[-1], wires=[n_qubits-1, 0])\n",
    "    for i in range(n_qubits-1):\n",
    "        qml.CRX(weights[i], wires=[i, (i+1)])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_X2(inputs, layer_weights):\n",
    "    qml.AngleEmbedding(features=inputs, wires=range(n_qubits))\n",
    "    for l in range(n_layers_circuit_X2):\n",
    "        circuit_X2_entangling(layer_weights[l], n_qubits)\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "weight_shapes_circuit_X2 = { \"layer_weights\": (n_layers_circuit_X2, n_qubits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_circuit_Z2 = 1\n",
    "def circuit_Z2_entangling(weights, n_qubits):\n",
    "    qml.CRZ(weights[-1], wires=[n_qubits - 1, 0])\n",
    "    for i in range(n_qubits - 1):\n",
    "        qml.CRZ(weights[i], wires=[i, i + 1])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_Z2(inputs, layer_weights):\n",
    "    qml.AngleEmbedding(features=inputs, wires=range(n_qubits))\n",
    "    for l in range(n_layers_circuit_Z2):\n",
    "        circuit_Z2_entangling(layer_weights[l], n_qubits)\n",
    "    return qml.probs(wires=range(n_qubits))\n",
    "weight_shapes_circuit_Z2 = { \"layer_weights\": (n_layers_circuit_Z2, n_qubits)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class Q_layer_angle(MessagePassing):\n",
    "    def __init__(self,src_dim, dst_dim, edge_dim, out_dim, **kwargs):\n",
    "        super(Q_layer_angle, self).__init__(aggr='mean')  \n",
    "        self.lin_res = qml.qnn.TorchLayer(circuit_X2, weight_shapes_circuit_X2)\n",
    "        self.lin_qml = qml.qnn.TorchLayer(circuit_Z2, weight_shapes_circuit_Z2)\n",
    "        self.in_linear = nn.Linear(src_dim + dst_dim + edge_dim, out_dim)\n",
    "        self.linear = nn.Linear(dst_dim, n_qubits)\n",
    "        self.bn = BN(32)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        feat_src, feat_dst = x\n",
    "        out = self.propagate(edge_index=edge_index, x=(feat_src, feat_dst), edge_attr=edge_attr)\n",
    "        out = out + self.lin_res(self.linear(feat_dst))\n",
    "        return self.bn(out)\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr):\n",
    "        out = torch.cat([x_j, x_i, edge_attr], dim=1)\n",
    "        out = self.in_linear(out)\n",
    "        out = self.lin_qml(out)\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_Hybrid_mid_angle(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGCN_Hybrid_mid_angle, self).__init__()\n",
    "        out_dim = n_qubits\n",
    "        edge_dim = 2\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer_angle(1, 1, edge_dim, out_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer_angle(1, 1, edge_dim,out_dim)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer_angle(32, 32, edge_dim, out_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer_angle(32, 32, edge_dim, out_dim)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv3 = HeteroConv({\n",
    "             ('UE', 'com-by', 'AP'): Q_layer_angle(32, 32, edge_dim, out_dim),\n",
    "             ('AP', 'com', 'UE'): Q_layer_angle(32, 32, edge_dim, out_dim)\n",
    "         }, aggr='mean')\n",
    "\n",
    "        self.mlp = MLP([32, 16])\n",
    "        self.mlp = nn.Sequential(*[self.mlp, Seq(Lin(16, 1), Sigmoid())])\n",
    "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
    "        out = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv2(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv3(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.mlp(out['UE'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qml_mid_angle = RGCN_Hybrid_mid_angle().to()\n",
    "\n",
    "optimizer_qml_mid_angle = torch.optim.Adam(model_qml_mid_angle.parameters(), lr=5e-4)\n",
    "scheduler_qml_mid_angle = torch.optim.lr_scheduler.StepLR(optimizer_qml_mid_angle, step_size=10, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model_qml_mid_angle.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_edge = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_rate = test_model(test_loader, model_qml_mid_angle)\n",
    "        train_rate = test_model(train_loader, model_qml_mid_angle)\n",
    "        record_edge.append([train_rate, test_rate])\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch:02d}, Train Rate: {train_rate:.4f}, Test Rate: {test_rate:.4f}')\n",
    "    train_model(epoch, model_qml_mid_angle, optimizer_qml_mid_angle, train_loader)\n",
    "    scheduler_qml_mid_angle.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output_qgnn = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "    gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_test_rates_q = rate_loss(output_qgnn, d_test, c_test, True).flatten().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(gnn_test_rates_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=180)\n",
    "epsilon = 0.001 \n",
    "\n",
    "positions_greater = np.where((gnn_test_rates_q - gnn_test_rates) > epsilon)[0]\n",
    "positions_equal = np.where(np.abs(gnn_test_rates_q - gnn_test_rates) <= epsilon)[0]\n",
    "\n",
    "count_greater = len(positions_greater)\n",
    "count_equal = len(positions_equal)\n",
    "count_not_greater = 200 - count_greater - count_equal\n",
    "\n",
    "labels = ['HQGNN angle > GNN', 'HQGNN angle ≈ GNN', 'HQGNN angle < GNN']\n",
    "sizes = [count_greater, count_equal, count_not_greater]\n",
    "explode = (0.1, 0.1, 0)  \n",
    "\n",
    "# Remove labels in the pie chart but keep legend\n",
    "ax.pie(sizes, explode=explode, labels=None, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(labels, loc='upper left')\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_rates_angle = None\n",
    "all_one_rates = None\n",
    "gnn_rates = None\n",
    "gnn_rates_amplitude = None\n",
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output1 = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output2 = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    gnn_rates = rate_loss(output, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_rates_amplitude = rate_loss(output1, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_rates_angle = rate_loss(output2, d_test, c_test, True).flatten().detach().numpy()\n",
    "    full = torch.ones_like(output)\n",
    "    all_one_rates = rate_loss(full, d_test, c_test, True).flatten().detach().numpy()\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = test_data['R_cf_opt_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rate, max_rate = 0, 2\n",
    "y_axis = np.arange(0, 1.0, 1/202)\n",
    "all_one_rates.sort()\n",
    "gnn_rates_angle.sort();opt_rates.sort();gnn_rates.sort();all_one_rates.sort();gnn_rates_amplitude.sort()\n",
    "gnn_rates_amplitude = np.insert(gnn_rates_amplitude, 0, min_rate); gnn_rates_amplitude = np.insert(gnn_rates_amplitude,201,max_rate)\n",
    "gnn_rates_angle = np.insert(gnn_rates_angle, 0, min_rate); gnn_rates_angle = np.insert(gnn_rates_angle,201,max_rate)\n",
    "gnn_rates = np.insert(gnn_rates, 0, min_rate); gnn_rates = np.insert(gnn_rates,201,max_rate)\n",
    "all_one_rates = np.insert(all_one_rates, 0, min_rate); all_one_rates = np.insert(all_one_rates,201,max_rate)\n",
    "opt_rates = np.insert(opt_rates, 0, min_rate); opt_rates = np.insert(opt_rates,201,max_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "fig, ax = plt.subplots(figsize=(6, 6), dpi=180)\n",
    "\n",
    "\n",
    "ax.plot(gnn_rates, y_axis, label='GNN', linestyle = '-',)\n",
    "ax.plot(gnn_rates_angle, y_axis, label='HQGNN angle', linestyle='--')\n",
    "ax.plot(gnn_rates_amplitude, y_axis, label='HQGNN amplitude', linestyle=':')\n",
    "ax.plot(opt_rates, y_axis, label='Optimal')\n",
    "ax.plot(all_one_rates, y_axis, label='Maximum Power')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Minimum rate [bps/Hz]')\n",
    "ax.set_ylabel('Empirical CDF')\n",
    "ax.legend(loc='upper left' )\n",
    "ax.grid()\n",
    "\n",
    "# Define the zoomed area\n",
    "x1, x2, y1, y2 = 1.04, 1.075, 0.5, 0.55\n",
    "\n",
    "axins = ax.inset_axes([0.75, 0.5, 0.2, 0.2])\n",
    "\n",
    "# Plot the same data on the inset\n",
    "axins.plot(gnn_rates, y_axis, label='GNN')\n",
    "axins.plot(gnn_rates_angle, y_axis, label='HQGNN angle', linestyle='--')\n",
    "axins.plot(gnn_rates_amplitude, y_axis, label='HQGNN amplitude', linestyle=':')\n",
    "axins.plot(opt_rates, y_axis, label='Optimal')\n",
    "axins.plot(all_one_rates, y_axis, label='Maximum Power')\n",
    "\n",
    "# Set the zoom limits on the inset\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "\n",
    "# Add zoom indication lines\n",
    "ax.indicate_inset_zoom(axins, edgecolor=\"black\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output_qgnn = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "    gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "    gnn_test_rates_q = rate_loss(output_qgnn, d_test, c_test, True).flatten().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_angle = []\n",
    "gnn_mid = []\n",
    "gnn = []\n",
    "opt = []\n",
    "\n",
    "for i in range(30, 91, 10):\n",
    "    open_file = 'cf_test_10_' + str(i) + '_min.mat'\n",
    "    data = scipy.io.loadmat(open_file)\n",
    "    beta = data['betas'][:100]\n",
    "    direct = data['directs'][:100]\n",
    "    cross = data['corsses'][:100].transpose(0, 2, 1)\n",
    "    opti = data['R_cf_opt_min'][:100]\n",
    "    \n",
    "    _, norm_losses = normalize_data(beta**(1/2), beta**(1/2))\n",
    "    data = PCDataset(norm_losses, direct, cross, (10, i))\n",
    "    loader = DataLoader(data, 100, shuffle=False, collate_fn=collate)\n",
    "    \n",
    "    gnn_angle_rates = []\n",
    "    gnn_mid_rates = []\n",
    "    gnn_rates = []\n",
    "    \n",
    "    for (data, d_test, c_test) in loader:\n",
    "        K = d_test.shape[-1]\n",
    "        n = len(data['UE'].x)\n",
    "        bs = len(data['UE'].x) // K\n",
    "        user_feats = data['AP'].x\n",
    "        item_feats = data['UE'].x\n",
    "        node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "        \n",
    "        output_qgnn_angle = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "        output_qgnn_mid = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "        output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "        \n",
    "        gnn_test_rates_angle = rate_loss(output_qgnn_angle, d_test, c_test, True).flatten().detach().numpy()\n",
    "        gnn_test_rates_mid = rate_loss(output_qgnn_mid, d_test, c_test, True).flatten().detach().numpy()\n",
    "        gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "        \n",
    "        gnn_angle_rates.append(np.mean(gnn_test_rates_angle))\n",
    "        gnn_mid_rates.append(np.mean(gnn_test_rates_mid))\n",
    "        gnn_rates.append(np.mean(gnn_test_rates))\n",
    "    \n",
    "    gnn_angle.append(np.mean(gnn_angle_rates))\n",
    "    gnn_mid.append(np.mean(gnn_mid_rates))\n",
    "    gnn.append(np.mean(gnn_rates))\n",
    "    opt.append(np.mean(opti)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['mathtext.fontset'] = 'cm'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "x_labels = list(range(30, 91, 10))\n",
    "x = np.arange(len(x_labels))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "width = 0.2\n",
    "\n",
    "plt.bar(x - 1.5 * width, gnn_angle, width, label='HQGNN angle', color='#87CEEB', hatch='.', edgecolor='black', alpha=0.85)  # Xanh dương nhạt\n",
    "plt.bar(x - 0.5 * width, gnn_mid, width, label='HQGNN amplitude', color='#FFB6A0', hatch='..', edgecolor='black', alpha=0.85)  # Cam nhạt\n",
    "plt.bar(x + 0.5 * width, gnn, width, label='GNN', color='#98FB98', edgecolor='black', alpha=0.85)  # Xanh lá nhạt\n",
    "plt.bar(x + 1.5 * width, opt, width, label='Optimal', color='#FFD700', hatch='...', edgecolor='black', alpha=0.85)  # Vàng nhạt\n",
    "\n",
    "plt.xlabel('Number of APs', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Average Rate', fontsize=14, fontweight='bold')\n",
    "plt.title('Comparison of Average Rates for Different Models-10UEs', fontsize=14, fontweight='bold')\n",
    "plt.xticks(x, x_labels, fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.legend(fontsize=14, loc='upper left', bbox_to_anchor=(1, 1), frameon=True, edgecolor='black')\n",
    "\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output_qgnn_angle = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_qgnn_amplitude = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "    gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "    qgnn_test_rates_a = rate_loss(output_qgnn_angle, d_test, c_test, True).flatten().detach().numpy()\n",
    "    qgnn_test_rates_q = rate_loss(output_qgnn_amplitude, d_test, c_test, True).flatten().detach().numpy()\n",
    "print(np.mean( qgnn_test_rates_a), np.mean(qgnn_test_rates_q), np.mean(gnn_test_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(-test_model(test_loader, model_qml_mid_angle),-test_model(test_loader, model_qml_amplitude),-test_model(test_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "models = {\n",
    "    \"GNN\": model,\n",
    "    \"HQGNN Amplitude\": model_qml_amplitude,\n",
    "    \"HQGNN Angle\": model_qml_mid_angle,\n",
    "}\n",
    "\n",
    "params_count = {name: sum(p.numel() for p in model.parameters()) for name, model in models.items()}\n",
    "for (data, d_test, c_test) in test_loader:\n",
    "    K = d_test.shape[-1]\n",
    "    n = len(data['UE'].x)\n",
    "    bs = len(data['UE'].x) // K\n",
    "    user_feats = data['AP'].x\n",
    "    item_feats = data['UE'].x\n",
    "    node_features = {'AP': user_feats, 'UE': item_feats}\n",
    "    output_qgnn_angle = model_qml_mid_angle(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_qgnn_amplitude = model_qml_amplitude(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs,-1)\n",
    "    output_gnn = model(node_features, data.edge_index_dict, data.edge_attr_dict).reshape(bs, -1)\n",
    "    gnn_test_rates = rate_loss(output_gnn, d_test, c_test, True).flatten().detach().numpy()\n",
    "    qgnn_test_rates_a = rate_loss(output_qgnn_angle, d_test, c_test, True).flatten().detach().numpy()\n",
    "    qgnn_test_rates_q = rate_loss(output_qgnn_amplitude, d_test, c_test, True).flatten().detach().numpy()\n",
    "\n",
    "avg_gnn_test_rates_angle = -test_model(test_loader, model_qml_mid_angle)\n",
    "avg_gnn_test_rates_amplitude = -test_model(test_loader, model_qml_amplitude)\n",
    "avg_gnn_test_rates = -test_model(test_loader, model)\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = np.mean(test_data['R_cf_opt_min'])\n",
    "\n",
    "\n",
    "performance_percentages = {\n",
    "    \"GNN\": (avg_gnn_test_rates / opt_rates) * 100,\n",
    "    \"HQGNN Amplitude\": (avg_gnn_test_rates_amplitude / opt_rates) * 100,\n",
    "    \"HQGNN Angle\": (avg_gnn_test_rates_angle / opt_rates) * 100,\n",
    "}\n",
    "data = {\n",
    "    \"Model\": [\"GNN\", \"HQGNN Amplitude\", \"HQGNN Angle\"],\n",
    "    \"Parameter Numbers\": [params_count[\"GNN\"], params_count[\"HQGNN Amplitude\"], params_count[\"HQGNN Angle\"]],\n",
    "    \"Performance (%)\": [performance_percentages[\"GNN\"], performance_percentages[\"HQGNN Amplitude\"], performance_percentages[\"HQGNN Angle\"]]\n",
    "}\n",
    "params_df = pd.DataFrame(data)\n",
    "print(params_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_parameters(model):\n",
    "    quantum_params = 0\n",
    "    classical_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lin_qml' in name or 'lin_res' in name:  # Phân loại các tham số thuộc về Quantum\n",
    "            quantum_params += param.numel()\n",
    "        else:  # Các tham số khác thuộc về Classical\n",
    "            classical_params += param.numel()\n",
    "    return quantum_params, classical_params\n",
    "models = {\n",
    "    \"GNN\": model,\n",
    "    \"HQGNN Amplitude\": model_qml_amplitude,\n",
    "    \"HQGNN Angle\": model_qml_mid_angle,\n",
    "}\n",
    "\n",
    "params_count = {\n",
    "    name: count_parameters(model)\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "avg_gnn_test_rates_angle = -test_model(test_loader, model_qml_mid_angle)\n",
    "avg_gnn_test_rates_amplitude = -test_model(test_loader, model_qml_amplitude)\n",
    "avg_gnn_test_rates = -test_model(test_loader, model)\n",
    "\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = np.mean(test_data['R_cf_opt_min'])\n",
    "\n",
    "# Tính hiệu suất\n",
    "performance_percentages = {\n",
    "    \"GNN\": (avg_gnn_test_rates / opt_rates) * 100,\n",
    "    \"HQGNN Amplitude\": (avg_gnn_test_rates_amplitude / opt_rates) * 100,\n",
    "    \"HQGNN Angle\": (avg_gnn_test_rates_angle / opt_rates) * 100,\n",
    "}\n",
    "\n",
    "# Tạo DataFrame chứa kết quả\n",
    "data = {\n",
    "    \"Model\": [\"GNN\", \"HQGNN Amplitude\", \"HQGNN Angle\"],\n",
    "    \"Classical Parameters\": [params_count[\"GNN\"][1], params_count[\"HQGNN Amplitude\"][1], params_count[\"HQGNN Angle\"][1]],\n",
    "    \"Quantum Parameters\": [params_count[\"GNN\"][0], params_count[\"HQGNN Amplitude\"][0], params_count[\"HQGNN Angle\"][0]],\n",
    "    \"Performance (%)\": [performance_percentages[\"GNN\"], performance_percentages[\"HQGNN Amplitude\"], performance_percentages[\"HQGNN Angle\"]]\n",
    "}\n",
    "params_df = pd.DataFrame(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Kích thước hình ảnh\n",
    "ax.axis('tight')  # Loại bỏ trục\n",
    "ax.axis('off')  # Loại bỏ viền trục\n",
    "table = ax.table(cellText=params_df.values, colLabels=params_df.columns, loc='center', cellLoc='center')\n",
    "\n",
    "# Tùy chỉnh bảng\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.auto_set_column_width(col=list(range(len(params_df.columns))))\n",
    "\n",
    "# Tăng khoảng cách giữa các hàng và cột\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_linewidth(1.5)  # Độ dày đường kẻ\n",
    "    cell.set_height(0.3)    # Tăng chiều cao hàng\n",
    "    cell.set_width(0.25)    # Tăng chiều rộng cột\n",
    "\n",
    "# Hiển thị bảng\n",
    "plt.savefig(\"model_parameters_and_performance_table_full.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_parameters.pth')\n",
    "#torch.save(model_qml_amplitude.state_dict(), 'model_amplitude_parameters.pth')\n",
    "# torch.save(model_qml_mid_angle.state_dict(), 'model_angle_parameters.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_parameters.pth'))\n",
    "model_qml_amplitude.load_state_dict(torch.load('model_amplitude_parameters.pth'))\n",
    "#model_qml_mid_angle.load_state_dict(torch.load('model_angle_parameters.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Same Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(channels, batch_norm=True):\n",
    "    return Seq(*[\n",
    "        Seq(Lin(channels[i - 1], channels[i]), ReLU(), BN(channels[i]))\n",
    "        for i in range(1, len(channels))\n",
    "    ])\n",
    "class EdgeConv_same(MessagePassing):\n",
    "    def __init__(self, input_dim, node_dim, dim_out, **kwargs):\n",
    "        super(EdgeConv_same, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin = MLP([input_dim, dim_out])\n",
    "        self.res_lin = Lin(node_dim, dim_out)\n",
    "        self.bn = BN(dim_out)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "\n",
    "        feat_src, feat_dst = x\n",
    "\n",
    "\n",
    "        out = self.propagate(edge_index=edge_index, x=(feat_src, feat_dst), edge_attr=edge_attr)\n",
    "\n",
    "\n",
    "        return self.bn(out + self.res_lin(feat_dst))\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr):\n",
    "        # Tạo ra thông điệp từ các nút nguồn, nút đích và đặc tính cạnh\n",
    "        out = torch.cat([x_j, x_i, edge_attr], dim=1)\n",
    "        return self.lin(out)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # Cập nhật giá trị nút đích sau khi tập hợp\n",
    "        return aggr_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_same(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGCN_same, self).__init__()\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv_same(4, 1, 13),\n",
    "            ('AP', 'com', 'UE'): EdgeConv_same(4, 1, 13)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv_same(28, 13, 13),\n",
    "            ('AP', 'com', 'UE'): EdgeConv_same(28, 13, 13)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv3 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): EdgeConv_same(28, 13, 13),\n",
    "            ('AP', 'com', 'UE'): EdgeConv_same(28, 13, 13)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.mlp = MLP([13, 20])\n",
    "        self.mlp = nn.Sequential(*[self.mlp, Seq(Lin(20, 1), Sigmoid())])\n",
    "    def forward(self,x_dict, edge_index_dict, edge_attr_dict):\n",
    "        out = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv2(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv3(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.mlp(out['UE'])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gnn = RGCN_same()\n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model_gnn.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HQGNN amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "\n",
    "n_qubits_amplitude = 4\n",
    "dev = qml.device('default.qubit', wires=n_qubits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_circuit_X = 2\n",
    "def circuit_X_entangling(weights, n_qubits_amplitude):\n",
    "    qml.CRX(weights[-1], wires=[n_qubits_amplitude-1, 0])\n",
    "    for i in range(n_qubits_amplitude-1):\n",
    "        qml.CRX(weights[i], wires=[i, (i+1)])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_X(inputs, layer_weights):\n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits_amplitude), normalize=True, pad_with=0.)\n",
    "    for l in range(n_layers_circuit_X):\n",
    "        circuit_X_entangling(layer_weights[l], n_qubits_amplitude)\n",
    "    return qml.probs(wires=range(n_qubits_amplitude))\n",
    "weight_shapes_circuit_X = { \"layer_weights\": (n_layers_circuit_X, n_qubits_amplitude)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers_circuit_Z = 2\n",
    "def circuit_Z_entangling(weights, n_qubits_amplitude):\n",
    "    qml.CRZ(weights[-1], wires=[n_qubits_amplitude - 1, 0])\n",
    "    for i in range(n_qubits_amplitude - 1):\n",
    "        qml.CRZ(weights[i], wires=[i, i + 1])\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def circuit_Z(inputs, layer_weights):\n",
    "    qml.AmplitudeEmbedding(features=inputs, wires=range(n_qubits_amplitude), normalize=True, pad_with=0.)\n",
    "    for l in range(n_layers_circuit_Z):\n",
    "        circuit_Z_entangling(layer_weights[l], n_qubits_amplitude)\n",
    "    return qml.probs(wires=range(n_qubits_amplitude))\n",
    "weight_shapes_circuit_Z = { \"layer_weights\": (n_layers_circuit_Z, n_qubits_amplitude)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Q_layer_same(MessagePassing):\n",
    "    def __init__(self,src_dim, dst_dim, edge_dim, **kwargs):\n",
    "        super(Q_layer_same, self).__init__(aggr='mean')  # mean aggregation\n",
    "        self.lin_res = qml.qnn.TorchLayer(circuit_Z, weight_shapes_circuit_Z)\n",
    "        self.lin_qml = qml.qnn.TorchLayer(circuit_X, weight_shapes_circuit_X)\n",
    "        self.in_linear = nn.Linear(src_dim + dst_dim + edge_dim, 2 ** n_qubits_amplitude)\n",
    "        self.bn = BN(2 ** n_qubits_amplitude)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        feat_src, feat_dst = x\n",
    "        out = self.propagate(edge_index=edge_index, x=(feat_src, feat_dst), edge_attr=edge_attr)\n",
    "        out = out + self.lin_res(feat_dst)\n",
    "        return self.bn(out)\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr):\n",
    "        out = torch.cat([x_j, x_i, edge_attr], dim=1)\n",
    "        out = self.in_linear(out)\n",
    "        out = self.lin_qml(out)\n",
    "        return out\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN_Hybrid_amplitude_same(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RGCN_Hybrid_amplitude_same, self).__init__()\n",
    "        out_dim = 2**n_qubits_amplitude\n",
    "        edge_dim = 2\n",
    "\n",
    "        self.conv1 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer_same(1, 1, edge_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer_same(1, 1, edge_dim,)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv2 = HeteroConv({\n",
    "            ('UE', 'com-by', 'AP'): Q_layer_same(out_dim, out_dim, edge_dim),\n",
    "            ('AP', 'com', 'UE'): Q_layer_same(out_dim, out_dim, edge_dim)\n",
    "        }, aggr='mean')\n",
    "\n",
    "        self.conv3 = HeteroConv({\n",
    "             ('UE', 'com-by', 'AP'): Q_layer_same(out_dim, out_dim, edge_dim),\n",
    "             ('AP', 'com', 'UE'): Q_layer_same(out_dim, out_dim, edge_dim)\n",
    "         }, aggr='mean')\n",
    "\n",
    "        self.mlp = MLP([16, 20])\n",
    "        self.mlp = nn.Sequential(*[self.mlp, Seq(Lin(20, 1), Sigmoid())])\n",
    "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
    "        out = self.conv1(x_dict, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv2(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.conv3(out, edge_index_dict, edge_attr_dict)\n",
    "        out = self.mlp(out['UE'])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_amplitude_same = RGCN_Hybrid_amplitude_same().to()\n",
    "\n",
    "optimizer_amplitude_same = torch.optim.Adam(model_amplitude_same.parameters(), lr=5e-4)\n",
    "scheduler_amplitude_same = torch.optim.lr_scheduler.StepLR(optimizer_amplitude_same, step_size=10, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = sum(p.numel() for p in model_amplitude_same.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "    if epoch % 1 == 0:\n",
    "        with torch.no_grad():\n",
    "            test_rate = test_model(test_loader, model_gnn)\n",
    "            train_rate = test_model(train_loader, model_gnn)\n",
    "        print(f'Epoch {epoch:03d}, Train Rate: {train_rate:.4f}, Test Rate: {test_rate:.4f}')\n",
    "        record.append([train_rate, test_rate])\n",
    "\n",
    "    train_model(epoch, model_gnn, optimizer, train_loader )\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_edge = []\n",
    "\n",
    "for epoch in range(0, 30):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        test_rate = test_model(test_loader, model_amplitude_same)\n",
    "        train_rate = test_model(train_loader, model_amplitude_same)\n",
    "        record_edge.append([train_rate, test_rate])\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch {epoch:02d}, Train Rate: {train_rate:.4f}, Test Rate: {test_rate:.4f}')\n",
    "    train_model(epoch, model_amplitude_same, optimizer_amplitude_same, train_loader)\n",
    "    scheduler_amplitude_same.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_gnn.state_dict(), 'model_gnn_same.pth')\n",
    "torch.save(model_amplitude_same.state_dict(), 'model_amplitude_same.pth')\n",
    "#torch.save(model_qml_mid_angle.state_dict(), 'model_angle_same.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_gnn.load_state_dict(torch.load('model_gnn_same.pth'))\n",
    "model_amplitude_same.load_state_dict(torch.load('model_amplitude_same.pth'))\n",
    "# model_qml_angle.load_state_dict(torch.load('model_angle_same.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Hàm để đếm tham số của mô hình\n",
    "def count_parameters(model):\n",
    "    quantum_params = 0\n",
    "    classical_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lin_qml' in name or 'lin_res' in name:  # Phân loại các tham số thuộc về Quantum\n",
    "            quantum_params += param.numel()\n",
    "        else:  # Các tham số khác thuộc về Classical\n",
    "            classical_params += param.numel()\n",
    "    return quantum_params, classical_params\n",
    "\n",
    "models = {\n",
    "    \"GNN\": model_gnn,\n",
    "    \"HQGNN Amplitude\": model_amplitude_same,\n",
    "    \"HQGNN Angle\": model_qml_mid_angle,\n",
    "}\n",
    "\n",
    "params_count = {\n",
    "    name: count_parameters(model)\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "avg_gnn_test_rates_angle = -test_model(test_loader, model_qml_mid_angle)\n",
    "avg_gnn_test_rates_amplitude = -test_model(test_loader, model_amplitude_same)\n",
    "avg_gnn_test_rates = -test_model(test_loader, model_gnn)\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = np.sum(test_data['R_cf_opt_min'])/len(test_loader.dataset)\n",
    "\n",
    "# Hiệu suất\n",
    "performance_percentages = {\n",
    "    \"GNN\": (avg_gnn_test_rates / opt_rates) * 100,\n",
    "    \"HQGNN Amplitude\": (avg_gnn_test_rates_amplitude / opt_rates) * 100,\n",
    "    \"HQGNN Angle\": (avg_gnn_test_rates_angle / opt_rates) * 100,\n",
    "}\n",
    "\n",
    "# Tạo DataFrame\n",
    "data = {\n",
    "    \"Model\": [\"GNN\", \"HQGNN Amplitude\", \"HQGNN Angle\"],\n",
    "    \"Classical Parameters\": [params_count[\"GNN\"][1], params_count[\"HQGNN Amplitude\"][1], params_count[\"HQGNN Angle\"][1]],\n",
    "    \"Quantum Parameters\": [params_count[\"GNN\"][0], params_count[\"HQGNN Amplitude\"][0], params_count[\"HQGNN Angle\"][0]],\n",
    "    \n",
    "    \"Performance (%)\": [performance_percentages[\"GNN\"], performance_percentages[\"HQGNN Amplitude\"], performance_percentages[\"HQGNN Angle\"]],\n",
    "}\n",
    "\n",
    "params_df = pd.DataFrame(data)\n",
    "\n",
    "print(params_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gnn_test_rates = None\n",
    "qgnn_test_rates_a = rate_loss(output_qgnn_angle, d_test, c_test, True).flatten().detach().numpy()\n",
    "qgnn_test_rates_q = rate_loss(output_qgnn_amplitude, d_test, c_test, True).flatten().detach().numpy()\n",
    "def count_parameters(model):\n",
    "    quantum_params = 0\n",
    "    classical_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'lin_qml' in name or 'lin_res' in name:  \n",
    "            quantum_params += param.numel()\n",
    "        else:  \n",
    "            classical_params += param.numel()\n",
    "    return quantum_params, classical_params\n",
    "\n",
    "models = {\n",
    "    \"GNN\": model_gnn,\n",
    "    \"HQGNN Amplitude\": model_amplitude_same,\n",
    "    \"HQGNN Angle\": model_qml_mid_angle,\n",
    "}\n",
    "\n",
    "params_count = {\n",
    "    name: count_parameters(model)\n",
    "    for name, model in models.items()\n",
    "}\n",
    "\n",
    "\n",
    "avg_gnn_test_rates_angle = -test_model(test_loader, model_qml_mid_angle)\n",
    "avg_gnn_test_rates_amplitude = -test_model(test_loader, model_amplitude_same)\n",
    "avg_gnn_test_rates = -test_model(test_loader, model_gnn)\n",
    "test_data = scipy.io.loadmat('cf_test_6_30.mat')\n",
    "opt_rates = np.sum(test_data['R_cf_opt_min'])/len(test_loader.dataset)\n",
    "    \n",
    "performance_percentages = {\n",
    "    \"GNN\": (avg_gnn_test_rates / opt_rates) * 100,\n",
    "    \"HQGNN Amplitude\": (avg_gnn_test_rates_amplitude / opt_rates) * 100,\n",
    "    \"HQGNN Angle\": (avg_gnn_test_rates_angle / opt_rates) * 100,\n",
    "}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"Model\": [\"GNN\", \"HQGNN Amplitude\", \"HQGNN Angle\"],\n",
    "    \"Classical Parameters\": [params_count[\"GNN\"][1], params_count[\"HQGNN Amplitude\"][1], params_count[\"HQGNN Angle\"][1]],\n",
    "    \"Quantum Parameters\": [params_count[\"GNN\"][0], params_count[\"HQGNN Amplitude\"][0], params_count[\"HQGNN Angle\"][0]],\n",
    "    \"Performance (%)\": [performance_percentages[\"GNN\"], performance_percentages[\"HQGNN Amplitude\"], performance_percentages[\"HQGNN Angle\"]],\n",
    "}\n",
    "params_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  \n",
    "ax.axis('tight')  \n",
    "ax.axis('off')  \n",
    "table = ax.table(cellText=params_df.values, colLabels=params_df.columns, loc='center', cellLoc='center')\n",
    "\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.auto_set_column_width(col=list(range(len(params_df.columns))))\n",
    "\n",
    "for (row, col), cell in table.get_celld().items():\n",
    "    cell.set_linewidth(1.5)  # Độ dày đường kẻ\n",
    "    cell.set_height(0.3)    # Tăng chiều cao hàng\n",
    "    cell.set_width(0.25) \n",
    "\n",
    "# Hiển thị bảng\n",
    "plt.savefig(\"model_parameters_table_from_code.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
